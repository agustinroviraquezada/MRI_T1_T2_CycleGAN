{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Introduction\n",
        "A model testing process was conducted using the BRATS2020 validation set. The validation set was downloaded and processed, and the resulting images were utilized for testing the model.\n",
        "\n",
        "BRATS2020 validation set can find here: https://www.kaggle.com/datasets/awsaf49/brats20-dataset-training-validation"
      ],
      "metadata": {
        "id": "VHx4ipptFFz-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get packages"
      ],
      "metadata": {
        "id": "rtBYQM1WFin-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "b06E4Htz-vr4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a522286c-c820-418b-d16b-58833abc2eef"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "_Hl5t6d4xa2F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53f7f647-6ac3-4eaa-c7be-5da1568066c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'MRI_T1_T2_CycleGAN'...\n",
            "remote: Enumerating objects: 1209, done.\u001b[K\n",
            "remote: Counting objects: 100% (451/451), done.\u001b[K\n",
            "remote: Compressing objects: 100% (168/168), done.\u001b[K\n",
            "remote: Total 1209 (delta 356), reused 356 (delta 280), pack-reused 758\u001b[K\n",
            "Receiving objects: 100% (1209/1209), 447.30 MiB | 43.58 MiB/s, done.\n",
            "Resolving deltas: 100% (755/755), done.\n",
            "Updating files: 100% (71/71), done.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m330.0/330.0 kB\u001b[0m \u001b[31m32.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.6/62.6 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.2/519.2 kB\u001b[0m \u001b[31m40.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.6/58.6 MB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m308.2/308.2 kB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m117.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m116.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m64.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.4/201.4 kB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m104.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.9/97.9 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.6/80.6 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.7/69.7 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.5/55.5 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m562.4/562.4 kB\u001b[0m \u001b[31m53.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.9/68.9 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m720.6/720.6 kB\u001b[0m \u001b[31m60.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.7/52.7 MB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.3/64.3 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.4/58.4 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.5/468.5 kB\u001b[0m \u001b[31m43.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.2/147.2 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.6/49.6 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.7/112.7 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for HD-BET (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for cycle (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for gpustat (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.27.1, but you have requests 2.31.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "!git clone https://github.com/agustinroviraquezada/MRI_T1_T2_CycleGAN.git\n",
        "requirements= \"/content/MRI_T1_T2_CycleGAN/requirements.txt\"\n",
        "!pip install -r $requirements -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nibabel as nib\n",
        "import glob\n",
        "import cv2\n",
        "from torchvision.transforms.functional import normalize\n",
        "import re\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from torchmetrics import StructuralSimilarityIndexMeasure as SSIM\n",
        "from torchmetrics import PeakSignalNoiseRatio as PSNR\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorboard.backend.event_processing.event_accumulator import EventAccumulator\n",
        "from cycle.CycleGAN import CycleGAN\n",
        "from cycle.DataMod import CycleGANDataModule,ImagePairTestSet\n",
        "import random\n",
        "import matplotlib.gridspec as gridspec\n",
        "import imageio.v2 as imageio\n",
        "from tqdm import tqdm\n",
        "random.seed(478)"
      ],
      "metadata": {
        "id": "mx8zzfGgrh0o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Unzip data and prepare folders T1 and T2"
      ],
      "metadata": {
        "id": "uBb4U2bpFnSW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/drive/MyDrive/Brats_Data/BraTS2020_ValidationData.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ddLEHkkca1Vw",
        "outputId": "cb567e7e-e058-4ae9-d532-56f3b0e60192"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/MyDrive/Brats_Data/BraTS2020_ValidationData.zip\n",
            "caution: filename not matched:  /content/drive/MyDrive/Brats_Data/MICCAI_BraTS2020_ValidationData\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def PipeLine(file_path,destiny,indices):\n",
        "\n",
        "    match = re.search(r\"(\\d+)_(t1|t2)\\.nii\", file_path)\n",
        "    subject_number = match.group(1)\n",
        "\n",
        "\n",
        "    center_slices=extract_center_slices(file_path,indices)\n",
        "    crop_slice=crop_images(center_slices)\n",
        "    ApplyOperations(crop_slice,destiny,subject_number,indices)\n",
        "\n",
        "\n",
        "\n",
        "def extract_center_slices(file_path,slices):\n",
        "    # Load the NIfTI file\n",
        "    img = nib.load(file_path)\n",
        "    data = img.get_fdata()\n",
        "\n",
        "    # Extract the center slices\n",
        "    center_slices=data[:, :, slices]\n",
        "    rotdata=np.rot90(center_slices,k=3)\n",
        "    ready_data=np.moveaxis(rotdata, 2, 0)\n",
        "    return ready_data\n",
        "\n",
        "\n",
        "\n",
        "def crop_images(data,margin=5,target_shape=(128, 128)):\n",
        "    crop = []\n",
        "\n",
        "    #Use a mask to find black margins and compute margings per each image\n",
        "    for img in data:\n",
        "        mask = img != 0\n",
        "        row_mask = np.any(mask, axis=1)\n",
        "        col_mask = np.any(mask, axis=0)\n",
        "\n",
        "        rmin = np.maximum(np.argmax(row_mask) - margin, 0)\n",
        "        rmax = row_mask.size - np.argmax(row_mask[::-1]) + margin\n",
        "        cmin = np.maximum(np.argmax(col_mask) - margin, 0)\n",
        "        cmax = col_mask.size - np.argmax(col_mask[::-1]) + margin\n",
        "\n",
        "        rmax = min(rmax, img.shape[0] - 1)\n",
        "        cmax = min(cmax, img.shape[1] - 1)\n",
        "\n",
        "        #Crop the image\n",
        "        cropped = img[rmin:rmax+1, cmin:cmax+1]\n",
        "        resized_img = cv2.resize(cropped, target_shape, interpolation=cv2.INTER_LINEAR)\n",
        "        crop.append(resized_img)\n",
        "\n",
        "    if not crop:\n",
        "        print(\"No images to stack. Please check the input data.\")\n",
        "        return np.array([])\n",
        "\n",
        "    return np.stack(crop)\n",
        "\n",
        "\n",
        "def ApplyOperations(img,destiny,subject_number,indices):\n",
        "    #re-scale image to 0-1\n",
        "    images_scaled = img / np.max(img, axis=(1, 2))[:, np.newaxis, np.newaxis]\n",
        "\n",
        "    # Convert the numpy array to a PyTorch tensor\n",
        "    img_tensor = torch.tensor(images_scaled, dtype=torch.float32).unsqueeze(1)\n",
        "\n",
        "    # Normalize the tensor with mean=0.5 and std=0.5\n",
        "    normalized_tensor = normalize(img_tensor, (0.5,), (0.5,))\n",
        "\n",
        "    for i,s in zip(normalized_tensor,indices):\n",
        "      torch.save(i,os.path.join(destiny,f\"B_{subject_number}_{s}.pt\"))"
      ],
      "metadata": {
        "id": "tfoPs0SkF1-_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rootFolder=\"/content/drive/MyDrive/Brats_Data/MICCAI_BraTS2020_ValidationData\"\n",
        "T1paths = glob.glob(rootFolder + \"/**/*_t1.nii\", recursive=True)\n",
        "T2paths = glob.glob(rootFolder + \"/**/*_t2.nii\", recursive=True)\n",
        "\n",
        "indices=[random.sample(range(70, 100), 5) for i in range(len(T1paths))]\n",
        "for t1,idx in zip(T1paths,indices): PipeLine(t1,\"/content/drive/MyDrive/Brats_Data/T1\",idx)\n",
        "for t2,idx in zip(T2paths,indices): PipeLine(t2,\"/content/drive/MyDrive/Brats_Data/T2\",idx)"
      ],
      "metadata": {
        "id": "WaKD_6xJcWBf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define functions"
      ],
      "metadata": {
        "id": "ZcZEifdYGG23"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ModelEvalBrats():\n",
        "  def __init__(self,dataloader,device='cuda'):\n",
        "\n",
        "    self.dataloader=dataloader\n",
        "    self.device=device\n",
        "\n",
        "  def RandomSamplePlot(self,ModelPath,mod):\n",
        "    params = {'lr'        : 0.0002,\n",
        "          'lbc_T1'        : 10,\n",
        "          'lbc_T2'        : 10,\n",
        "          'lbi'           : 0.1,\n",
        "          'b1'            : 0.5,\n",
        "          'b2'            : 0.999,\n",
        "          'batch_size'    : 1,\n",
        "          'im_channel'    : 1,\n",
        "          'n_epochs'      : 9000,     #When it start. High number to not apply this\n",
        "          'n_epochs_decay': 9000,     #Every each epoch to do High number to not apply this\n",
        "          'mode'          : \"linear\",\n",
        "          \"target_shape\"  : 1,\n",
        "          \"resnet_neck\"   : 6,\n",
        "          \"features\"      : 64}\n",
        "\n",
        "    model2=CycleGAN(params)\n",
        "    model2load=model2.load_from_checkpoint(checkpoint_path=ModelPath)\n",
        "\n",
        "    # Instantiate your CycleGAN class (assuming it is already trained)\n",
        "    model2load.eval()  # Set the model to evaluation mode\n",
        "    model2load.to(self.device)  # Assuming you're using GPU\n",
        "    ct=0\n",
        "    T1_sample,T2_sample,T1f_sample,T2f_sample,T1C_sample,T2C_sample,T1I_sample,T2I_sample,names=[],[],[],[],[],[],[],[],[]\n",
        "    T1_siimf,T1_ssimc,T1_ssimi,T2_siimf,T2_ssimc,T2_ssimi=[],[],[],[],[],[]\n",
        "    ssim = SSIM().to(self.device)\n",
        "\n",
        "    for T1,T2,T1_name,T2_name in self.dataloader:\n",
        "      if random.random()>0.5:\n",
        "        ct+=1\n",
        "        T1 = T1.to(self.device)\n",
        "        T2 = T2.to(self.device)\n",
        "\n",
        "        T1_sample.append(torch.squeeze(T1.to(\"cpu\")).numpy())\n",
        "        T2_sample.append(torch.squeeze(T2.to(\"cpu\")).numpy())\n",
        "\n",
        "        match = re.search(r\"B_(\\d+)_(\\d+)\\.pt\",T1_name[0])\n",
        "        num1 = match.group(1)\n",
        "        num2 = match.group(2)\n",
        "        expression = f\"S {int(num1)} S {int(num2)}\"\n",
        "        names.append(expression)\n",
        "\n",
        "\n",
        "\n",
        "        # Generate a T2w image\n",
        "        with torch.no_grad():  # Inference only\n",
        "            T1_f=model2load.G_T2_T1(T2)\n",
        "            T2_f=model2load.G_T1_T2(T1)\n",
        "\n",
        "            T1_C=model2load.G_T2_T1(T2_f)\n",
        "            T2_C=model2load.G_T1_T2(T1_f)\n",
        "\n",
        "            T1_I=model2load.G_T2_T1(T1)\n",
        "            T2_I=model2load.G_T1_T2(T2)\n",
        "\n",
        "\n",
        "\n",
        "        T1f_sample.append(torch.squeeze(T1_f.to(\"cpu\")).numpy())\n",
        "        T2f_sample.append(torch.squeeze(T2_f.to(\"cpu\")).numpy())\n",
        "        T1C_sample.append(torch.squeeze(T1_C.to(\"cpu\")).numpy())\n",
        "        T2C_sample.append(torch.squeeze(T2_C.to(\"cpu\")).numpy())\n",
        "        T1I_sample.append(torch.squeeze(T1_I.to(\"cpu\")).numpy())\n",
        "        T2I_sample.append(torch.squeeze(T2_I.to(\"cpu\")).numpy())\n",
        "\n",
        "\n",
        "        T1_siimf.append(ssim(T1_f, T1).to(\"cpu\").detach().item())\n",
        "        T1_ssimc.append(ssim(T1_C, T1).to(\"cpu\").detach().item())\n",
        "        T1_ssimi.append(ssim(T1_I, T1).to(\"cpu\").detach().item())\n",
        "        T2_siimf.append(ssim(T2_f, T2).to(\"cpu\").detach().item())\n",
        "        T2_ssimc.append(ssim(T2_C, T2).to(\"cpu\").detach().item())\n",
        "        T2_ssimi.append(ssim(T2_I, T2).to(\"cpu\").detach().item())\n",
        "\n",
        "\n",
        "\n",
        "      if ct==5:\n",
        "        break\n",
        "\n",
        "    #T1 -->T2\n",
        "    gs = gridspec.GridSpec(5, 5)  # Increase number of rows, one set of rows for images and one for histogram.\n",
        "    fig = plt.figure(figsize=(10,12))  # Increase the height of the figure\n",
        "    for t1,t2,t2f,t2c,t2i,sf,sc,si,ri,na in zip(T1_sample,T2_sample,T2f_sample,T2C_sample,T2I_sample,T2_siimf,T2_ssimc,T2_ssimi,range(6),names):\n",
        "\n",
        "      ax1 = fig.add_subplot(gs[ri, 0])\n",
        "      ax1.imshow(t1, cmap='gray')\n",
        "      ax1.set_title(f'T1w {na}', size=10)\n",
        "      ax1.axis('off')\n",
        "\n",
        "      ax2 = fig.add_subplot(gs[ri, 1])\n",
        "      ax2.imshow(t2, cmap='gray')\n",
        "      ax2.set_title(f'T2w {na}', size=10)\n",
        "      ax2.axis('off')\n",
        "\n",
        "      ax3 = fig.add_subplot(gs[ri, 2])\n",
        "      ax3.imshow(t2f, cmap='gray')\n",
        "      ax3.set_title(f'sT2w SSIM:{sf:.2f}', size=10)\n",
        "      ax3.axis('off')\n",
        "\n",
        "      ax3 = fig.add_subplot(gs[ri, 3])\n",
        "      ax3.imshow(t2c, cmap='gray')\n",
        "      ax3.set_title(f'cT2w SSIM:{sc:.2f}', size=10)\n",
        "      ax3.axis('off')\n",
        "\n",
        "      ax4 = fig.add_subplot(gs[ri, 4])\n",
        "      ax4.imshow(t2i, cmap='gray')\n",
        "      ax4.set_title(f'iT2w SSIM:{si:.2f}', size=10)\n",
        "      ax4.axis('off')\n",
        "\n",
        "    plt.suptitle(\"Sample Real vs Generated T2\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f\"Plot_SampleEval_T2_Images_{mod}.svg\", format='svg')\n",
        "    plt.show()\n",
        "\n",
        "    fig, axs = plt.subplots(5, 1, figsize=(10,12)) # Increase the height of the figure\n",
        "    for t1,t2,t2f,t2c,t2i,sf,sc,si,ri,na in zip(T1_sample,T2_sample,T2f_sample,T2C_sample,T2I_sample,T2_siimf,T2_ssimc,T2_ssimi,range(6),names):\n",
        "      axs[ri].hist(t2.flatten(), bins=100, density=True, histtype='step',facecolor='k',range=(-1,1),label=\"T2W\")\n",
        "      axs[ri].hist(t2f.flatten(), bins=100, density=True, histtype='step',facecolor='r',range=(-1,1),label=\"sT2W\")\n",
        "      axs[ri].hist(t2c.flatten(), bins=100, density=True, histtype='step',facecolor='b',range=(-1,1),label=\"cT2W\")\n",
        "      axs[ri].hist(t2i.flatten(), bins=100, density=True, histtype='step',facecolor='g',range=(-1,1),label=\"iT2W\")\n",
        "\n",
        "      axs[ri].set_xlim(-0.95,1)\n",
        "      axs[ri].set_ylim(0,4)\n",
        "      axs[ri].set_title(f'Intensity Distribution {na}')\n",
        "      axs[ri].set_xlabel('Intensity', size=10)\n",
        "      axs[ri].set_ylabel('Frequency', size=10)\n",
        "      axs[ri].legend()\n",
        "\n",
        "    plt.suptitle(\"Sample Real vs Generated T2\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f\"Plot_SampleEval_T2_Histogram_{mod}.svg\", format='svg')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    #T2 -->T1\n",
        "    gs = gridspec.GridSpec(5, 5)  # Increase number of rows, one set of rows for images and one for histogram.\n",
        "    fig = plt.figure(figsize=(10,12))  # Increase the height of the figure\n",
        "    for t2,t1,t1f,t1c,t1i,sf,sc,si,ri,na in zip(T2_sample,T1_sample,T1f_sample,T1C_sample,T1I_sample,T1_siimf,T1_ssimc,T1_ssimi,range(6),names):\n",
        "\n",
        "      ax1 = fig.add_subplot(gs[ri, 0])\n",
        "      ax1.imshow(t2, cmap='gray')\n",
        "      ax1.set_title(f'T2w {na}', size=10)\n",
        "      ax1.axis('off')\n",
        "\n",
        "      ax2 = fig.add_subplot(gs[ri, 1])\n",
        "      ax2.imshow(t1, cmap='gray')\n",
        "      ax2.set_title(f'T1w {na}', size=10)\n",
        "      ax2.axis('off')\n",
        "\n",
        "      ax3 = fig.add_subplot(gs[ri, 2])\n",
        "      ax3.imshow(t1f, cmap='gray')\n",
        "      ax3.set_title(f'sT1w SSIM:{sf:.2f}', size=10)\n",
        "      ax3.axis('off')\n",
        "\n",
        "      ax3 = fig.add_subplot(gs[ri, 3])\n",
        "      ax3.imshow(t1c, cmap='gray')\n",
        "      ax3.set_title(f'cT1w SSIM:{sc:.2f}', size=10)\n",
        "      ax3.axis('off')\n",
        "\n",
        "      ax4 = fig.add_subplot(gs[ri, 4])\n",
        "      ax4.imshow(t1i, cmap='gray')\n",
        "      ax4.set_title(f'iT1w SSIM:{si:.2f}', size=10)\n",
        "      ax4.axis('off')\n",
        "\n",
        "    plt.suptitle(\"Sample Real vs Generated T1\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f\"Plot_SampleEval_T1_Images_{mod}.svg\", format='svg')\n",
        "    plt.show()\n",
        "\n",
        "    fig, axs = plt.subplots(5, 1, figsize=(10,12)) # Increase the height of the figure\n",
        "    for t2,t1,t1f,t1c,t1i,sf,sc,si,ri,na in zip(T2_sample,T1_sample,T1f_sample,T1C_sample,T1I_sample,T1_siimf,T1_ssimc,T1_ssimi,range(6),names):\n",
        "      axs[ri].hist(t1.flatten(), bins=100, density=True, histtype='step',facecolor='k',range=(-1,1),label=\"T2W\")\n",
        "      axs[ri].hist(t1f.flatten(), bins=100, density=True, histtype='step',facecolor='r',range=(-1,1),label=\"sT2W\")\n",
        "      axs[ri].hist(t1c.flatten(), bins=100, density=True, histtype='step',facecolor='b',range=(-1,1),label=\"cT2W\")\n",
        "      axs[ri].hist(t1i.flatten(), bins=100, density=True, histtype='step',facecolor='g',range=(-1,1),label=\"iT2W\")\n",
        "\n",
        "      axs[ri].set_xlim(-0.95,1)\n",
        "      axs[ri].set_ylim(0,4)\n",
        "      axs[ri].set_title(f'Intensity Distribution {na}')\n",
        "      axs[ri].set_xlabel('Intensity', size=10)\n",
        "      axs[ri].set_ylabel('Frequency', size=10)\n",
        "      axs[ri].legend()\n",
        "\n",
        "    plt.suptitle(\"Sample Real vs Generated T1\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f\"Plot_SampleEval_T1_Histogram_{mod}.svg\", format='svg')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  def GetMetrics(self,ModelPath):\n",
        "    params = {'lr'        : 0.0002,\n",
        "          'lbc_T1'        : 10,\n",
        "          'lbc_T2'        : 10,\n",
        "          'lbi'           : 0.1,\n",
        "          'b1'            : 0.5,\n",
        "          'b2'            : 0.999,\n",
        "          'batch_size'    : 1,\n",
        "          'im_channel'    : 1,\n",
        "          'n_epochs'      : 9000,     #When it start. High number to not apply this\n",
        "          'n_epochs_decay': 9000,     #Every each epoch to do High number to not apply this\n",
        "          'mode'          : \"linear\",\n",
        "          \"target_shape\"  : 1,\n",
        "          \"resnet_neck\"   : 6,\n",
        "          \"features\"      : 64}\n",
        "\n",
        "    model2=CycleGAN(params)\n",
        "    self.model2load=model2.load_from_checkpoint(checkpoint_path=ModelPath)\n",
        "\n",
        "\n",
        "    # Instantiate your CycleGAN class (assuming it is already trained)\n",
        "    self.model2load.eval()  # Set the model to evaluation mode\n",
        "    self.model2load.to(self.device)  # Assuming you're using GPU\n",
        "    Metrics=[]\n",
        "\n",
        "    for T1,T2,T1_name,T2_name in tqdm(self.dataloader):\n",
        "      T1_metics,T2_metrics=self.Compute_Metrics(T1,T2,T1_name,T2_name,ModelPath)\n",
        "      Metrics.append(T1_metics)\n",
        "      Metrics.append(T2_metrics)\n",
        "\n",
        "    df=pd.DataFrame(Metrics,columns=[\"File\",\"Modality\",\"SSIM_C\",\"SSIM_F\",\"PSNR_C\",\"PSNR_F\",\"I_SSIM\",\"I_PSNR\"])\n",
        "    result=df.groupby(['Modality']).agg(['mean','max', 'std']).reset_index()\n",
        "\n",
        "    return result,df\n",
        "\n",
        "  def Compute_Metrics(self,T1,T2,T1_name,T2_name,ModelPath):\n",
        "    T1 = T1.to(self.device)\n",
        "    T2 = T2.to(self.device)\n",
        "    model=os.path.basename(ModelPath)\n",
        "\n",
        "    # Generate a T2w image\n",
        "    with torch.no_grad():  # Inference only\n",
        "        f_T1 = self.model2load.G_T2_T1(T2)\n",
        "        f_T2 = self.model2load.G_T1_T2(T1)\n",
        "\n",
        "        C_T1=self.model2load.G_T2_T1(f_T2)\n",
        "        C_T2=self.model2load.G_T1_T2(f_T2)\n",
        "\n",
        "        I_T1=self.model2load.G_T2_T1(T1)\n",
        "        I_T2=self.model2load.G_T1_T2(T2)\n",
        "\n",
        "    #Define Metrics\n",
        "    psnr= PSNR().to(self.device)\n",
        "    ssim = SSIM().to(self.device)\n",
        "\n",
        "\n",
        "    #SIIM\n",
        "    C_T1_SSIM= ssim(C_T1, T1).to(\"cpu\").detach().item()\n",
        "    F_T1_SSIM= ssim(f_T1, T1).to(\"cpu\").detach().item()\n",
        "    I_T1_SSIM= ssim(I_T1, T1).to(\"cpu\").detach().item()\n",
        "\n",
        "    C_T2_SSIM= ssim(C_T2, T2).to(\"cpu\").detach().item()\n",
        "    F_T2_SSIM= ssim(f_T2, T2).to(\"cpu\").detach().item()\n",
        "    I_T2_SSIM= ssim(I_T2, T2).to(\"cpu\").detach().item()\n",
        "\n",
        "\n",
        "    #PNRS\n",
        "    C_T1_PSNR= psnr(C_T1, T1).to(\"cpu\").detach().item()\n",
        "    F_T1_PSNR= psnr(f_T1, T1).to(\"cpu\").detach().item()\n",
        "    I_T1_PSNR= psnr(I_T1, T1).to(\"cpu\").detach().item()\n",
        "\n",
        "    C_T2_PSNR= psnr(C_T2, T2).to(\"cpu\").detach().item()\n",
        "    F_T2_PSNR= psnr(f_T2, T2).to(\"cpu\").detach().item()\n",
        "    I_T2_PSNR= psnr(I_T2, T2).to(\"cpu\").detach().item()\n",
        "\n",
        "\n",
        "    return (T1_name[0],\"T1\",C_T1_SSIM,F_T1_SSIM,C_T1_PSNR,F_T1_PSNR,I_T1_SSIM,I_T1_PSNR),(T2_name[0],\"T2\",C_T2_SSIM,F_T2_SSIM,C_T2_PSNR,F_T2_PSNR,I_T2_SSIM,I_T2_PSNR)"
      ],
      "metadata": {
        "id": "YMBMSax2_qPA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing"
      ],
      "metadata": {
        "id": "QIcBSG1ZGLWH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DataPath={\"T1\":\"/content/drive/MyDrive/Brats_Data/T1\",\"T2\":\"/content/drive/MyDrive/Brats_Data/T2\"}\n",
        "TestPath={\"T1\":\"/content/drive/MyDrive/Brats_Data/T1\",\"T2\":\"/content/drive/MyDrive/Brats_Data/T2\"}\n",
        "dataset=ImagePairTestSet(DataPath,TestPath,prb=0.09)\n",
        "DataMRI_test = DataLoader(dataset, batch_size=1, shuffle=True)\n",
        "Evaluacion=ModelEvalBrats(DataMRI_test,device='cuda')"
      ],
      "metadata": {
        "id": "HEwpRfHWr8Vg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ModelPath=\"/content/MRI_T1_T2_CycleGAN/Models/BaseLine_model_0.694-276.ckpt\"\n",
        "Metrics,d_Baseline= Evaluacion.GetMetrics(ModelPath)\n",
        "Metrics.to_csv(\"/content/MRI_T1_T2_CycleGAN/Models/MetricsBaseline_BestModel_informe.csv\")\n",
        "\n",
        "ModelPath=\"/content/MRI_T1_T2_CycleGAN/Models/Optimized_model_0.690-290.ckpt\"\n",
        "Evaluacion.RandomSamplePlot(ModelPath,\"Baseline\")"
      ],
      "metadata": {
        "id": "yDugWyNRsQxY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}